{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gav-ip/cse176-fall-proj/blob/part2/xgboost_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9af3547",
      "metadata": {
        "id": "a9af3547"
      },
      "source": [
        "#**XG Boost**\n",
        "Change runtime type to T4 GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fc8d10f",
      "metadata": {
        "id": "7fc8d10f"
      },
      "outputs": [],
      "source": [
        "# skip if on google colab\n",
        "%pip install -r ../requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "71b52927",
      "metadata": {
        "id": "71b52927"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bae8f2c",
      "metadata": {
        "id": "0bae8f2c"
      },
      "source": [
        "#**LOAD MNIST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e8dcc9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e8dcc9f",
        "outputId": "4ae59f35-82f9-41eb-d7ee-2617cdc8fd60"
      },
      "outputs": [],
      "source": [
        "mnist = loadmat('MNIST.mat')\n",
        "\n",
        "# Extract data\n",
        "X_train_full = mnist['train_fea']\n",
        "y_train_full = mnist['train_gnd'].ravel()\n",
        "X_test = mnist['test_fea']\n",
        "y_test = mnist['test_gnd'].ravel()\n",
        "\n",
        "# Split training into train and validation (55k train, 5k val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=5000, random_state=42)\n",
        "\n",
        "# shift labels to 0-9\n",
        "y_train = y_train - 1\n",
        "y_val = y_val - 1\n",
        "y_test = y_test - 1\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de1044d4",
      "metadata": {
        "id": "de1044d4"
      },
      "source": [
        "#**MODEL FITTING AND EARLY STOPPING**\n",
        "*- ran on Google Colab T4 GPU*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w9Mhe4BzYCgr",
      "metadata": {
        "id": "w9Mhe4BzYCgr"
      },
      "outputs": [],
      "source": [
        "# Early stopping callback to prevent overfitting\n",
        "early_stop = xgb.callback.EarlyStopping(\n",
        "    rounds=20,\n",
        "    metric_name='mlogloss',\n",
        "    data_name='validation_0',\n",
        "    save_best=True,\n",
        "    min_delta=1e-3    # (default 1e-2) Improvement threshold for continued training, decreasing to prevent premature stopping or increase to mitigate overfitting\n",
        ")\n",
        "# Use \"hist\" for constructing the trees, with early stopping enabled.\n",
        "clf = xgb.XGBClassifier(\n",
        "    tree_method=\"hist\",\n",
        "    n_estimators=2000,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    device = 'cuda',\n",
        "    max_depth = 6,   # Balanced value of ranges of max_depth of the decision tree to prevent overfitting\n",
        "    callbacks=[early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6Gc4yvZiGaJ2",
      "metadata": {
        "id": "6Gc4yvZiGaJ2"
      },
      "source": [
        "## Fitting model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kJaUxNj_ALFX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJaUxNj_ALFX",
        "outputId": "a7e64231-afe6-43a4-a10b-695a02607fcd"
      },
      "outputs": [],
      "source": [
        "# Fitting model using train and validation sets\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    verbose=False  # Set to True if you want to see the log stream for training (validation_0) and validation (validation_1)\n",
        ")\n",
        "\n",
        "results = clf.evals_result()\n",
        "\n",
        "epochs = len(results['validation_0']['mlogloss'])\n",
        "x_axis = range(0, epochs)\n",
        "print(\"done fitting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62fbc793",
      "metadata": {
        "id": "62fbc793"
      },
      "source": [
        "#**Performance Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32de8452",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "32de8452",
        "outputId": "7651b518-c827-4f07-aafe-5ea86e0b8804"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.axvline(x=clf.best_iteration, color='r', linestyle='--', alpha=0.7, label=f'Best iteration = {clf.best_iteration}')\n",
        "\n",
        "plt.plot(x_axis, results['validation_0']['mlogloss'], label='Training Log Loss')\n",
        "plt.plot(x_axis, results['validation_1']['mlogloss'], label='Validation Log Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs (Boosting Rounds)')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title('XGBoost Log Loss: Training vs Validation')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best model found at iteration: {clf.best_iteration}\")\n",
        "\n",
        "# This automatically uses the best iteration\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy (using best model): {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "952237c0",
      "metadata": {
        "id": "952237c0"
      },
      "source": [
        "#**Generate confusion matrix**\n",
        "evaluating on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "624da534",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "624da534",
        "outputId": "e411213d-b11c-491f-86de-a19c3cafb323"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "            cm,\n",
        "            cmap=\"magma\",\n",
        "            annot=True,\n",
        "            fmt=\"d\",\n",
        "            cbar=True,\n",
        "        )\n",
        "plt.title('Confusion Matrix: MNIST Digit Classification', fontsize=14)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_test_pred, digits=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65ef25d0",
      "metadata": {},
      "source": [
        "#**Load LeNet5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "658e9fb7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys in .mat file:  dict_keys(['__header__', '__version__', '__globals__', 'test_fea', 'test_gnd', 'train_fea', 'train_gnd'])\n",
            "Training set: (55000, 800), (55000,)\n",
            "Validation set: (5000, 800), (5000,)\n",
            "Test set: (10000, 800), (10000,)\n"
          ]
        }
      ],
      "source": [
        "LeNet = loadmat('../data/MNIST-LeNet5.mat')\n",
        "\n",
        "print(\"Keys in .mat file: \", LeNet.keys())\n",
        "\n",
        "# Extract data\n",
        "X_train_full = LeNet['train_fea']\n",
        "y_train_full = LeNet['train_gnd'].ravel()\n",
        "X_test = LeNet['test_fea']\n",
        "y_test = LeNet['test_gnd'].ravel()\n",
        "\n",
        "# Split training into train and validation (55k train, 5k val)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=5000, random_state=42)\n",
        "\n",
        "# shift labels to 0-9\n",
        "y_train = y_train - 1\n",
        "y_val = y_val - 1\n",
        "y_test = y_test - 1\n",
        "\n",
        "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda797cc",
      "metadata": {},
      "source": [
        "#**MODEL FITTING AND EARLY STOPPING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2f5d2ab4",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'xgb' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Early stopping callback to prevent overfitting\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m early_stop = \u001b[43mxgb\u001b[49m.callback.EarlyStopping(\n\u001b[32m      3\u001b[39m     rounds=\u001b[32m20\u001b[39m,\n\u001b[32m      4\u001b[39m     metric_name=\u001b[33m'\u001b[39m\u001b[33mmlogloss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      5\u001b[39m     data_name=\u001b[33m'\u001b[39m\u001b[33mvalidation_0\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m     save_best=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      7\u001b[39m     min_delta=\u001b[32m1e-3\u001b[39m    \u001b[38;5;66;03m# (default 1e-2) Improvement threshold for continued training, decreasing to prevent premature stopping or increase to mitigate overfitting\u001b[39;00m\n\u001b[32m      8\u001b[39m )\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Use \"hist\" for constructing the trees, with early stopping enabled.\u001b[39;00m\n\u001b[32m     11\u001b[39m clf = xgb.XGBClassifier(\n\u001b[32m     12\u001b[39m     tree_method=\u001b[33m\"\u001b[39m\u001b[33mhist\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     n_estimators=\u001b[32m2000\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     callbacks=[early_stop]\n\u001b[32m     18\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'xgb' is not defined"
          ]
        }
      ],
      "source": [
        "# Early stopping callback to prevent overfitting\n",
        "early_stop = xgb.callback.EarlyStopping(\n",
        "    rounds=20,\n",
        "    metric_name='mlogloss',\n",
        "    data_name='validation_0',\n",
        "    save_best=True,\n",
        "    min_delta=1e-3    # (default 1e-2) Improvement threshold for continued training, decreasing to prevent premature stopping or increase to mitigate overfitting\n",
        ")\n",
        "\n",
        "# Use \"hist\" for constructing the trees, with early stopping enabled.\n",
        "clf = xgb.XGBClassifier(\n",
        "    tree_method=\"hist\",\n",
        "    n_estimators=2000,\n",
        "    eval_metric=\"mlogloss\",\n",
        "    device = 'cuda',\n",
        "    max_depth = 6,   # Balanced value of ranges of max_depth of the decision tree to prevent overfitting\n",
        "    callbacks=[early_stop]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70177a8d",
      "metadata": {},
      "source": [
        "#Fitting Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f4bad8d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fitting model using train and validation sets\n",
        "clf.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    verbose=False  # Set to True if you want to see the log stream for training (validation_0) and validation (validation_1)\n",
        ")\n",
        "\n",
        "results = clf.evals_result()\n",
        "\n",
        "epochs = len(results['validation_0']['mlogloss'])\n",
        "x_axis = range(0, epochs)\n",
        "print(\"done fitting\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c4276c",
      "metadata": {},
      "source": [
        "#**Performance Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf6f848",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.axvline(x=clf.best_iteration, color='r', linestyle='--', alpha=0.7, label=f'Best iteration = {clf.best_iteration}')\n",
        "\n",
        "plt.plot(x_axis, results['validation_0']['mlogloss'], label='Training Log Loss')\n",
        "plt.plot(x_axis, results['validation_1']['mlogloss'], label='Validation Log Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs (Boosting Rounds)')\n",
        "plt.ylabel('Log Loss')\n",
        "plt.title('XGBoost Log Loss: Training vs Validation')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Best model found at iteration: {clf.best_iteration}\")\n",
        "\n",
        "# This automatically uses the best iteration\n",
        "y_test_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate test accuracy\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "print(f\"Test Accuracy (using best model): {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "516a8dd1",
      "metadata": {},
      "source": [
        "#**Generate confusion matrix**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f705746",
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "            cm,\n",
        "            cmap=\"magma\",\n",
        "            annot=True,\n",
        "            fmt=\"d\",\n",
        "            cbar=True,\n",
        "        )\n",
        "plt.title('Confusion Matrix: MNIST Digit Classification', fontsize=14)\n",
        "plt.xlabel('Predicted Label', fontsize=12)\n",
        "plt.ylabel('True Label', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_test, y_test_pred, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
